"""The tracking tool aims to provide a CLI for two important tracking tools.

We can generate tracking data for a given run of PROCESS, which corresponds to one output MFile.
When generating tracking data, we store metadata about the run, such as time and commit message,
and also variable data: the value of a given variable during this run; this is all stored in one
JSON file.

* Run title: the name of the run input, and hence output, file (e.g. baseline 2018).
* Tracking history: the data held within all JSON files in the database that span many variables,
many different run titles and spans a period of time.
* Variable history: the data held within all JSON files in the database for a given variable;
not all run titles will have a history for each variable being tracked
* A run of PROCESS: refers to the output MFile from the running of one input file
* JSON file: holds the metadata, and tracking data, generated by a run of PROCESS

We can also plot a database of JSON files. The tracking history (ie all the data) must be loaded
before being processed into a dataframe. This dataframe is then processed into a tracking dashboard:

* The dashboard: represented by the entire html file generated, contains many panels
* Panels: each parent module (or variable namespace) has its own tab which contains many graphs
* Graphs: each graph shows the variable history of one variable, it will have many lines
* Lines: each line represents many datapoints for a single variable, over a period of time,
that all come from the same run title
* Datapoints: the value of a variable at a point in time during a given run


To add a variable to track:

Add the variable to ProcessTracker.tracking_variables (in this file).
If the variable is not a fortran module variable, ensure to override its parent module name
e.g. FOO.bar says `bar`'s parent module is `FOO`.
"""

import argparse
import datetime
import itertools
import json
import logging
import math
import pathlib
from typing import ClassVar

import git
import pandas as pd
from bokeh.embed import file_html
from bokeh.layouts import gridplot
from bokeh.models import (
    ColumnDataSource,
    DatetimeTickFormatter,
    HoverTool,
    TabPanel,
    Tabs,
)
from bokeh.palettes import Category10
from bokeh.plotting import figure
from bokeh.resources import CDN

from process.io import mfile as mf

logging.basicConfig(level=logging.INFO, filename="tracker.log")
logger = logging.getLogger("PROCESS Tracker")

DEFAULT_TRACKING_VARIABLES = {
    "CurrentDrive.p_hcd_primary_extra_heat_mw",
    "CurrentDrive.f_c_plasma_bootstrap",
    "CurrentDrive.p_hcd_injected_total_mw",
    "Build.dr_shld_inboard",
    "Build.dr_fw_inboard",
    "Build.dr_fw_outboard",
    "Build.dr_tf_shld_gap",
    "Build.dr_bore",
    "Build.dr_cs",
    "Build.dr_fw_plasma_gap_inboard",
    "Build.dr_blkt_outboard",
    "Build.dr_cs_precomp",
    "Build.dr_tf_outboard",
    "Build.dr_blkt_inboard",
    "Build.dr_shld_blkt_gap",
    "Build.dr_fw_plasma_gap_outboard",
    "Build.dr_cs_tf_gap",
    "Build.dr_shld_vv_gap_outboard",
    "Build.dr_shld_outboard",
    "Build.dr_tf_inboard",
    "Build.dr_shld_vv_gap_inboard",
    "FWBSVariables.p_shld_nuclear_heat_mw",
    "FWBSVariables.p_blkt_nuclear_heat_total_mw",
    "Physics.triang",
    "Physics.triang95",
    "Physics.p_plasma_inner_rad_mw",
    "Physics.temp_plasma_separatrix_kev",
    "Physics.f_nd_alpha_electron",
    "Physics.pflux_fw_neutron_mw",
    "Physics.aspect",
    "Physics.rminor",
    "Physics.rmajor",
    "Physics.q95",
    "Physics.temp_plasma_electron_vol_avg_kev",
    "Physics.beta_total_vol_avg",
    "Physics.f_c_plasma_inductive",
    "Physics.n_charge_plasma_effective_vol_avg",
    "Physics.b_plasma_toroidal_on_axis",
    "Physics.hfact",
    "Physics.kappa",
    "Physics.p_fusion_total_mw",
    "Physics.temp_plasma_pedestal_kev",
    "Physics.p_plasma_loss_mw",
    "Physics.kappa95",
    "Physics.nd_plasma_pedestal_electron",
    "Physics.nd_plasma_electrons_vol_avg",
    "Physics.p_plasma_rad_mw",
    "Physics.nd_plasma_electron_on_axis",
    "Physics.f_c_plasma_auxiliary",
    "Physics.nd_plasma_impurities_vol_avg",
    "Physics.t_energy_confinement",
    "Physics.temp_plasma_electron_on_axis_kev",
    "Physics.p_plasma_separatrix_mw",
    "Physics.nd_plasma_separatrix_electron",
    "Physics.vol_plasma",
    "Physics.a_plasma_surface",
    "HeatTransport.p_plant_electric_net_mw",
    "HeatTransport.eta_turbine",
    "HeatTransport.p_plant_electric_gross_mw",
    "TFCoil.tftmp",
    "TFCoil.n_tf_coils",
    "TFCoil.b_tf_inboard_peak_symmetric",
    "PFCoil.vs_cs_pf_total_pulse",
    "Physics.nd_plasma_ions_total_vol_avg",
    "Time.t_plant_pulse_burn",
    "Cost.life_div_fpy",
    "Cost.cdirt",
    "Cost.concost",
}
"""Variables of the form: <system>.<variable>
where <system> is an arbitrary name that categorises the variables
and <variable> is present in the tracked MFile
"""

# Tracking


class TrackingFile:
    """Acts as the data storage for a given JSON file ie. holds the data from a run of PROCESS

    e.g. starfire_MFILE-<date>-<time>.json
    """

    def __init__(self) -> None:
        self.meta: dict = {}
        # metadata (e.g. commit message and date generated) as a key-value pair

        self.tracking: dict = {}
        # tracking data that shows the value of an important variable as a key-value pair

    def asdict(self) -> dict:
        return {"meta": self.meta, "tracking": self.tracking}


class ProcessTracker:
    """Manages the creation of tracking data into a JSON file for a run of PROCESS."""

    meta_variables: ClassVar = {"date", "time"}
    # Variables in an MFile that hold metadata we want to show on the graph

    def __init__(
        self,
        mfile: str,
        database: str | None = None,
        message: str | None = None,
        hashid: str | None = None,
        tracking_variables_file: pathlib.Path | None = None,
        strict: bool = False,
    ) -> None:
        """Drive the creation of tracking JSON files.

        :param mfile: the path to an mfile to create tracking data for.
        :type mfile: str

        :param database: the folder (acting as a database) that stores all tracking JSON files
        :type database: str
        """
        self.mfile = mf.MFile(mfile)

        if strict and (ifail := self.mfile.data["ifail"].get_scan(-1)) != 1:
            raise RuntimeError(
                f"{ifail = :.0f} indicates PROCESS has failed to converge."
            )

        self.tracking_file = TrackingFile()

        if tracking_variables_file is None:
            self.tracking_variables = DEFAULT_TRACKING_VARIABLES
        else:
            with open(tracking_variables_file) as f:
                self.tracking_variables = json.load(f)

        self._generate_data()

        title = pathlib.Path(mfile).stem
        self.add_extra_metadata("title", title)

        commit_message = message or git.git_commit_message()
        self.add_extra_metadata("commit_message", commit_message)
        commit_hash = hashid or git.git_commit_hash()
        self.add_extra_metadata("commit_hash", commit_hash)

        if database:
            # split to remove timezone from date if present
            date = self.tracking_file.meta.get("date").replace("/", "").split(" ")[0]
            time = self.tracking_file.meta.get("time")

            # for an mfile called foo.MFILE.DAT created at 16:00 on 15/11/2021
            # the tracking data file will be written to
            # foo_MFILE-15112021-16:00.json
            tracking_file_name = pathlib.Path(database) / f"{title}-{date}-{time}.json"

            self.write(tracking_file_name)

    def add_extra_metadata(self, key, value):
        """Enables the adding of extra metadata of key: value"""
        self.tracking_file.meta[key] = value

    def _generate_data(self):
        """
        Generates metadata for all metadata variables in ProcessTracker.meta_variables
        Generates tracking data for all variables in ProcessTracker.tracking_variables.

        Extracts the various meta/variable data from the mfile into our internal
        data store
        """
        # meta data
        for var in self.meta_variables:
            try:
                # value of var in the mfile
                variable_data = self.mfile.data[var]
            except KeyError:
                logger.info(f"{var} is not present in the MFile and will be skipped.")
                continue

            self.tracking_file.meta[var] = variable_data.get_scan(1)

        # tracking data
        for var in self.tracking_variables:
            if "." in var:
                # a dotted variable is for variables that no longer exist in Fortran module variables
                # see tracking_variables docstring
                try:
                    _, var = var.split(".")
                except (AttributeError, ValueError):
                    logger.warning(
                        f"{var} is a dotted variable and must be in the form OVERRIDINGNAME.VARIABLE"
                    )

            # value of the variable extracted from the mfile
            mfile_var_value = self.mfile.data[var]

            if isinstance(mfile_var_value, mf.MFileErrorClass):
                logger.info(f"{var} is not present in the MFile and will be skipped.")
                continue

            if mfile_var_value.get_number_of_scans() > 1:
                logger.info(
                    f"Only scan 1 will be tracked, but {var} has {mfile_var_value.get_number_of_scans()} scans."
                )

            self.tracking_file.tracking[var] = mfile_var_value.get_scan(1)

    def write(self, filename: str):
        """Write the metadata and tracking data into the JSON file"""
        with open(filename, "w") as f:
            json.dump(self.tracking_file.asdict(), f, indent=4)


# Plotting

colour_map = {}
colours = itertools.cycle(
    Category10[10]
)  # hardcode at 10 meaning a maximum of 10 different line colours


def get_line_colour(title: str):
    """Given a run title, return either cached colour or pick a colour and then cache it."""
    if title in colour_map:
        return colour_map[title]

    colour = next(colours)
    colour_map[title] = colour

    return colour


class TrackedVariable:
    """
    Holds the variable history, over all runs that produced this variable in their output,
    of this variable.
    """

    def __init__(self, name: str) -> None:
        self.name = name
        # Name of the graph this variable is plotted under
        self._data = []
        # Tuple of (title, timestamp, data, message, hash)

        # title: name of the run e.g. starfire or baseline_2018 (not unique)
        # timestamp: date of the specific run this tuple refers to (unique)
        # data: the value of the variable, `name`, on `title` run at time `date` (possibly unique)
        # message: latest commit message when `title` was run at time `date` (possibly unique)
        # hash: latest commit hash when `title` was run at time `date` (possibly unique)

    def add_datapoint(self, title, data, message, commit_hash, timestamp):
        """
        Adds a tuple to this graph

        title: name of the run e.g. starfire or baseline_2018 (not unique)
        timestamp: date of the specific run this tuple refers to (unique)
        data: the value of the variable, `name`, on `title` run at time `date` (possibly unique)
        message: latest commit message when `title` was run at time `date` (possibly unique)
        """
        self._data.append((title, timestamp, data, message, commit_hash))

    def as_dataframe(self):
        """
        Converts our internal data representation of this variable's history as a dataframe.

        title -> title
        timestamp -> date
        data -> value
        message -> annotation
        """
        df = pd.DataFrame(self._data)
        df.columns = ("title", "date", "value", "commit", "commit_id")

        return df


class TrackedData:
    """Holds the entire tracking history of a database"""

    def __init__(self, database) -> None:
        self.database = pathlib.Path(database)

        self.tracked_variables = {}
        # Each tracked variable corresponds to a TrackedVariable

        self._track()

    def _add_variables(self, json_file_data):
        """Adds the `data` of an entire JSON tracking
        file to an internal store before being
        transformed into a dataframe, to then be plotted.
        """

        # extract the metadata from our file as all datapoints of this file will require them
        metadata = json_file_data["meta"]
        title = metadata.get("title", "-")
        message = metadata.get("commit_message", "-")
        hash_ = metadata.get("commit_hash", "-")
        # split to disregard timezone if present
        date_str = metadata.get("date", "-").split(" ")[0]
        time_str = metadata.get("time", "-")

        # common format for the timestamp of the run
        data_time_str = f"{date_str.strip()} - {time_str.strip()}"
        date_time = datetime.datetime.strptime(
            data_time_str, "%d/%m/%Y - %H:%M"
        ).replace(tzinfo=datetime.timezone.utc)

        tracking_data = json_file_data.get(
            "tracking", []
        )  # the JSON data of one run of PROCESS in python datastructures
        for variable, value in tracking_data.items():
            # create a new TrackedVariable when we see a variable we do not know
            if variable not in self.tracked_variables:
                self.tracked_variables[variable] = TrackedVariable(variable)

            self.tracked_variables.get(variable).add_datapoint(
                title, value, message, hash_, date_time
            )

    def _track(self):
        """Loads the entire history, for all runs that are stored in the database."""
        # open all files in the `database` folder

        for i in self.database.glob("*.json"):
            with open(i) as f:
                file_data = json.load(f)  # parsed contents of the JSON tracking file
                self._add_variables(
                    file_data
                )  # add all the data in this JSON file to our internal store


def plot_tracking_data(database, tracked_variables):
    """
    Drives the processing of existing .json tracking files and then plotting of this processed data.
    """
    loaded_tracking_database_data = TrackedData(database)
    # data is our entire database of JSON files loaded and processed

    figures = {}

    variable_parent_map = {}
    # holds a map of variable parent's names overriden using the . (dot) syntax
    # variable: parent module name

    # populates the overrides map
    for i in tracked_variables:
        parent_name, variable = i.split(".")
        variable_parent_map[variable] = parent_name

    for variable, history in loaded_tracking_database_data.tracked_variables.items():
        df = (
            history.as_dataframe()
        )  # all the data for one tracked variable as a dataframe

        # order by date to avoid polygons all over the plot
        df = df.sort_values("date", ascending=True)

        parent = variable_parent_map.get(variable)

        # if a variable does not have a parent, then it has been removed
        # from the tracking list and we skip it.
        if parent is None:
            continue

        if figures.get(parent) is None:
            figures[parent] = []

        titles = list(
            df["title"].to_numpy()
        )  # all scenarios this variable is tracked in

        figur = figure(title=variable, x_axis_type="datetime", width=600, height=600)
        figur.xaxis.formatter = DatetimeTickFormatter(
            hours="%d %B %Y",
            days="%d %B %Y",
            months="%d %B %Y",
            years="%d %B %Y",
        )
        figur.xaxis.major_label_orientation = math.pi / 4

        # each title (different scenario) has a different line colour
        for t in set(titles):
            run_title_dataframe = df[
                df["title"] == t
            ]  # the variable history for each (applicable) run title
            subsource = ColumnDataSource(
                run_title_dataframe
            )  # convert dataframe into Bokeh compatible
            colour = get_line_colour(t)

            figur.scatter(
                x="date", y="value", source=subsource, legend_label=t, color=colour
            )

            figur.line(
                x="date",
                y="value",
                source=subsource,
                legend_label=t,
                color=colour,
                line_color=colour,
            )

        figur.legend.click_policy = "hide"  # hide a line if its legend entry is clicked

        # show a title, commit, and date when hovering over a datapoint
        hovertool = HoverTool(
            tooltips=[
                ("Title", "@title"),
                ("Commit", "@commit"),
                ("Commit ID", "@commit_id"),
                ("Date", "@date{%Y-%m-%d %H:%M}"),
            ],
            formatters={
                "@title": "printf",
                "@date": "datetime",
                "@commit": "printf",
                "@commit_id": "printf",
            },
        )

        # each section of the legend is next to each other
        # in a line rather than the default stack
        figur.legend.orientation = "horizontal"

        # legend is positioned in the x center
        figur.legend.location = "center"

        # legend is above the actual figure
        # so as not to cover the data
        figur.add_layout(figur.legend[0], "above")

        figur.add_tools(hovertool)

        figures[parent].append(figur)

    panels = []

    # each module/overriden name e.g. CostModel2 has a panel which holds graphs for all variables under that scope
    for parent_module_name, figs in figures.items():
        if len(figs) % 2 != 0:
            gplot = gridplot([figs[i : i + 2] for i in range(0, len(figs), 2)])
        else:
            gplot = gridplot([figs[i : i + 2] for i in range(0, len(figs) - 1, 2)])

        panels.append(TabPanel(child=gplot, title=parent_module_name))

    tabs = Tabs(tabs=panels)

    # returns the entire HTML document (to be written to a file)
    return file_html(tabs, CDN, "PROCESS Regression Testing Visualisation")


def write_tracking_html_file(database, output, tracking_variables_file):
    """Writes the visual tracking data to an appropriate file"""

    if tracking_variables_file is None:
        tracked_variables = DEFAULT_TRACKING_VARIABLES
    else:
        with open(tracking_variables_file) as f:
            tracked_variables = json.load(f)

    tracking_html = plot_tracking_data(database, tracked_variables)

    with open(output, "w") as f:
        f.write(tracking_html)


def track_entrypoint(arguments):
    """
    Entrypoint if we run in track mode.

    Generates a tracking JSOn file for the provided MFile.
    """
    if not arguments.mfile:
        raise ValueError("track requires --mfile be set")

    ProcessTracker(
        mfile=arguments.mfile,
        database=arguments.db,
        message=arguments.commit,
        hashid=arguments.hash,
        tracking_variables_file=arguments.tracking_variables_file,
    )


def plot_entrypoint(arguments):
    """
    Entrypoint if we run in plot mode.

    Plots all tracking data into a single tracking.html file
    """
    if not arguments.out:
        raise ValueError("plot requires --out be set")

    write_tracking_html_file(
        database=arguments.db,
        output=arguments.out,
        tracking_variables_file=arguments.tracking_variables_file,
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument("mode", type=str, choices=["track", "plot"])

    parser.add_argument("db", type=str)
    parser.add_argument("-o", "--out", type=str, default=None)
    parser.add_argument("-m", "--mfile", type=str, default=None)
    parser.add_argument(
        "--commit",
        type=str,
        default=None,
        help="The current commit message. If not provided, the code attempts to query to Git repository.",
    )
    parser.add_argument(
        "--hash",
        type=str,
        default=None,
        help="The current commit hash. If not provided, the code attempts to query to Git repository.",
    )
    parser.add_argument(
        "--tracking-variables-file",
        type=pathlib.Path,
        default=None,
        help="A JSON file containing a list of variables to track."
        "See the description of DEFAULT_TRACKING_VARIABLES for details on formatting the strings in the list.",
    )

    arguments = parser.parse_args()

    if arguments.mode == "track":
        track_entrypoint(arguments)
    elif arguments.mode == "plot":
        plot_entrypoint(arguments)
