# ---
# jupyter:
#   jupytext:
#     cell_metadata_filter: tags,-all
#     formats: py:percent,ipynb
#     notebook_metadata_filter: -jupytext.text_representation.jupytext_version
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#   kernelspec:
#     display_name: Python 3 (ipykernel)
#     language: python
#     name: python3
# ---

# %% [markdown]
# # Introduction to running PROCESS
#
# A Jupyter notebook to demonstrate usage of the `process` package.
#
# Process can be run from the command line with the `process` command or as a standard python package.
# Using process as a package allows for more complex scripting of a process run for different tasks.
#
# ## Setup
# We run the examples in a temporary directory so all the inputs are copied there and the outputs
# contained there before the directory is removed when the example has finished running.
# This keeps the examples directory tidy and does not permanently modify any data files.
# Use of temporary directories is not needed for regular use of `PROCESS`.

# %% [markdown]
# ## Basic run of Process
# Run Process on an input file using the `SingleRun` class. This outputs an `MFILE.DAT` and an `OUT.DAT`.
#
# This is equivalent to running `process -i data/large_tokamak_IN.DAT` in the examples folder.

# %%
# %load_ext autoreload
# %autoreload 2

import shutil
import tempfile
from pathlib import Path

from process.main import SingleRun

# Define project root dir; this is using the current working directory
PROJ_DIR = Path.cwd().parent

# Define input file name relative to project dir, then copy to temp dir
script_dir = Path("__file__").parent.resolve()
input_file = script_dir / "data/large_tokamak_IN.DAT"

# Copy the file to avoid polluting the project directory with example files
temp_dir = tempfile.TemporaryDirectory()
input_path = Path(temp_dir.name) / "large_tokamak_IN.DAT"
shutil.copy(input_file, input_path)

# Run process on an input file in a temporary directory
single_run = SingleRun(input_path.as_posix())
single_run.run()

# %% [markdown]
# ## Plot summary
# Create a summary of the generated `MFILE.DAT` using `plot_proc`.
#
# You can also call `plot_proc` from the cli with `python -m process.io.plot_proc`

# %%
from process.io import plot_proc

# Pdf and png output are also available
plot_proc.main(
    args=["-f", single_run.mfile_path.as_posix(), "--output-format", "none", "--show"]
)

# %% [markdown]
# ## View key output variables
# Using the `MFILE` we generated by running the large tokamak scenario above,
# we have set some values on the `CostModel` instance and can print them.

# %%
import process.data_structure

# Print some values on the CostModel instance
print(f"Heat transport system: {process.data_structure.cost_variables.c226:.3e} M$")
print(f"Electrical plant equipment: {process.data_structure.cost_variables.c24:.3e} M$")

# %% [markdown]
# ## Convert to CSV format
# This demonstrates how you would read from a PROCESS MFILE and write specified values into a csv using the `mfile_to_csv` function

# %%
from process.io import mfile_to_csv

data_dir = Path("data")

# mfile_to_csv requires two inputs:
# - path to the MFILE
# - .json containing the variable names to include in the csv file

# This routine attempts to find every variable listed in the json file
# in the MFILE and writes the variable name, description and value
# to the output csv.
# Any listed variable that isn't in that MFILE will be skipped.
# The .csv file is saved to the directory of the input file

mfile_to_csv.main(
    args=[
        "-f",
        (data_dir / "large_tokamak_1_MFILE.DAT").as_posix(),
        "-v",
        (data_dir / "mfile_to_csv_vars.json").as_posix(),
    ]
)

# %%
# Clean up
temp_dir.cleanup()
